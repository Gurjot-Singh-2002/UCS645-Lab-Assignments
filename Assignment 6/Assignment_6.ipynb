{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP27nKRG/wN6LvYyDz7cmLp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gurjot-Singh-2002/UCS645-Lab-Assignments/blob/main/Assignment%206/Assignment_6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Gurjot Singh 102203582 3CO14"
      ],
      "metadata": {
        "id": "8Na1OMtoS0xh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Program 1"
      ],
      "metadata": {
        "id": "ddkQEuS2S_SK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile sqrt_cuda.cu\n",
        "#include <stdio.h>\n",
        "#include <math.h>\n",
        "#include <cuda.h>\n",
        "\n",
        "// CUDA kernel to compute the square root of each element in array A and store in C\n",
        "__global__ void sqrtKernel(float *A, float *C, int N) {\n",
        "    int idx = threadIdx.x + blockDim.x * blockIdx.x;  // Global thread index\n",
        "    if (idx < N)\n",
        "        C[idx] = sqrtf(A[idx]);  // Compute square root of A[idx] and store in C[idx]\n",
        "}\n",
        "\n",
        "// Function to allocate memory, copy data, launch kernel, and measure time\n",
        "void runSqrt(int N) {\n",
        "    float *A, *C;        // Host arrays\n",
        "    float *d_A, *d_C;    // Device arrays\n",
        "\n",
        "    size_t size = N * sizeof(float);  // Total memory size\n",
        "\n",
        "    // Allocate memory on host\n",
        "    A = (float *)malloc(size);\n",
        "    C = (float *)malloc(size);\n",
        "\n",
        "    // Initialize array A with values 1 to N\n",
        "    for (int i = 0; i < N; i++)\n",
        "        A[i] = (float)(i + 1);\n",
        "\n",
        "    // Allocate memory on device (GPU)\n",
        "    cudaMalloc((void **)&d_A, size);\n",
        "    cudaMalloc((void **)&d_C, size);\n",
        "\n",
        "    // Copy input array A from host to device\n",
        "    cudaMemcpy(d_A, A, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Set the number of threads per block and blocks per grid\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // Create CUDA events for timing\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "\n",
        "    // Start recording time\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // Launch the CUDA kernel\n",
        "    sqrtKernel<<<blocksPerGrid, threadsPerBlock>>>(d_A, d_C, N);\n",
        "\n",
        "    // Stop recording time\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);  // Wait for kernel to finish\n",
        "\n",
        "    // Calculate elapsed time in milliseconds\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    // Print the size and execution time\n",
        "    printf(\"N = %d, Time = %.4f ms\\n\", N, milliseconds);\n",
        "\n",
        "    // Copy result array C from device to host\n",
        "    cudaMemcpy(C, d_C, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Free allocated memory\n",
        "    cudaFree(d_A);\n",
        "    cudaFree(d_C);\n",
        "    free(A);\n",
        "    free(C);\n",
        "\n",
        "    // Destroy CUDA events\n",
        "    cudaEventDestroy(start);\n",
        "    cudaEventDestroy(stop);\n",
        "}\n",
        "\n",
        "// Main function to test with different input sizes\n",
        "int main() {\n",
        "    runSqrt(50000);\n",
        "    runSqrt(500000);\n",
        "    runSqrt(5000000);\n",
        "    runSqrt(50000000);\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U-69kAi4TXGj",
        "outputId": "98d91081-70c7-4a96-a7fb-c1299df20b7e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting sqrt_cuda.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Program Compilation---"
      ],
      "metadata": {
        "id": "WKv5DTtOcSwS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc --gpu-architecture=sm_70 sqrt_cuda.cu -o sqrt_cuda\n"
      ],
      "metadata": {
        "id": "NRtor-64WFip"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Program Execution---"
      ],
      "metadata": {
        "id": "uCoDrNT0cU_k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!./sqrt_cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pVikchuCWJXM",
        "outputId": "601a67b9-a896-4413-a76e-f1260eb7bab7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "N = 50000, Time = 0.1689 ms\n",
            "N = 500000, Time = 0.0274 ms\n",
            "N = 5000000, Time = 0.1908 ms\n",
            "N = 50000000, Time = 1.8307 ms\n"
          ]
        }
      ]
    }
  ]
}